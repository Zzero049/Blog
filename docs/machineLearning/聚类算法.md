<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>

# 聚类算法
聚类和分类任务不同点在于训练数据有无标签

## K-MEANS
* 算法接受参数k；然后将事先输入的n个数据对象划分为k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。
* 算法思想：以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果

#### 步骤
1. 先从没有标签的元素集合A中随机取k个元素，作为k个子集各自的重心。
2. 分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧氏距离），根据距离将这些元素分别划归到最近的子集。
3. 根据聚类结果，重新计算重心（重心的计算方法是计算子集中所有元素各个维度的算数平均数）。
4. 将集合A中全部元素按照新的重心然后再重新聚类。
5. 重复第4步，直到聚类结果不再发生变化。
#### 例子
以下4个样本中，要分为两个类
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 220942.png"  div align=center />

计算各点到中心点的距离
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 222608.png"  div align=center />

通过计算的距离，由于第二类样本超过规定的2个，更新第二类的中心，还要再计算到中心距离，并更新中心
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 222343.png"  div align=center />

聚类不发生变化，算法迭代停止
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 221054.png"  div align=center />

迭代对聚类中心的影响：
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 222035.png"  div align=center />

对k个初始质心的选择比较敏感，容易陷入局部最小值。
例如，我们上面的算法运行的时候，有可能会得到不同的结果，如下面这两种情况。K-means也是收敛了，只是收敛到了局部最小值：

<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 155704.png"  div align=center />

解决方案：
使用对质心取多次的随机初始化，计算每一次建模得到的代价函数的值，选取代价函数最小结果作为聚类结果。
```
For i=1 to 100{
    Randomly initialize K-means.
    Run K-means.Get
    Compute cost function(distortion)
}
```
代价函数公式：
$$J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_k)=\frac{1}{m}\sum_{i=1}^{m}||x^{(i)}-\mu_{c^{(i)}}||^2$$

一共有m个样本，$\mu$为质心坐标，$x^{(i)}-\mu_{c^{(i)}}$为$x^{(i)}$样本所属质心$\mu_{c^{(i)}}$的距离


k值的选择是用户指定的，不同的k得到的结果会有挺大的不同，如下图所示，左边是k=3的结果，蓝色的簇太稀疏了，蓝色的簇应该可以再划分成两个簇。右边是k=5的结果，红色和蓝色的簇应该合并为一个簇。
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 132542.png"  div align=center />
解决方案：
* 使用肘部法选择k的值
通过代价函数做图看出是否有类似肘部的存在，确定k值
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 153815.png"  div align=center />

k-means可视化
https://www.naftaliharris.com/blog/visualizing-k-means-clustering/

## DBSCAN
基于密度的方法：DBSCAN(Density-Based Spatial Clustering of Applications with Noise)
本算法将具有足够高密度的区域划分为簇，并可以发现任何形状的聚类

**$\epsilon$邻域：** 给定对象半径$\epsilon$内的区域称为该对象的$\epsilon$邻域。
**核心对象：** 如果给定$\epsilon$邻域内的样本点数大于等于Minpoints（圈内规定最少有多少个样本点），则该对象为核心对象。
**直接密度可达：** 给定一个对象集合D，如果p在q的e邻域内，且q是一个核心对象，则我们说对象p从q触发是直接密度可达的（directly density-reachable）。
**密度可达：** 集合D，存在一个对象链
p1，p2...pn，p1=q，pn=p，pi+1是从pi关于a和Minpoints直接密度可达，则称点p是从q关于和Minpoints密度可达的。(2个直接密度可达，通过传递性，P、Q密度可达)
**密度相连：** 集合D存在点o，使得点p、q是从o关于和Minpoints密度可达的，那么点p、q是关于e和Minpoints密度相连的。（2个密度可达都通过一点O完成，则R，S为密度相连）
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 154043.png"  div align=center />

#### 算法思想
1. 指定合适的$\epsilon$和Minpoints。
2. 计算所有的样本点，如果点p的$\epsilon$邻域里有超过Minpoints个点，则创建一个以p为核心点的新族。
3. 反复寻找这些核心点直接密度可达（之后可能是密度可达）的点，将其加入到相应的簇，对于核心点发生“密度相连"
状况的簇，给予合并。
4. 当没有新的点可以被添加到任何簇时，算法结束。
##### 缺点：
* 当数据量增大时，要求较大的内存支持I/O消耗也很大。
 * 当空间聚类的密度不均匀、聚类间距差相差很大时，聚类质量较差。

DBSCAN和K-MEANS比较：
* DBSCAN不需要输入聚类个数。
* 聚类簇的形状没有要求。
* 可以在需要时输入过滤噪声的参数。

DBSCAN可视化：
https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/