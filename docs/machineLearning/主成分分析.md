<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>

# 主成分分析PCA（Principal Component Analysis）

是一种降维方法
例如：

<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 203145.png"  div align=center />

<center>二维转一维</center>
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 195216.png"  div align=center />

<center>三维转二维</center>

#### 降维分析
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 203450.png"  div align=center />
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 195100.png"  div align=center />

##### PCA不是线性回归
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 203723.png"  div align=center />

### 算法流程
1. 数据预处理：中心化$X-\overline{X}$。(所有数据减平均值)
2. 求样本的协方差矩阵$\frac{1}{m}XX^T$。
3. 对协方差$\frac{1}{m}XX^T$矩阵做特征值分解。
4. 选出最大的k个特征值对应的k个特征向量。
5. 将原始数据投影到选取的特征向量上。
6. 输出投影后的数据集。

协方差描述两个数据的相关性，接近1就是正相关，接近-1就是负相关，接近0就是不相关。
协方差公式：
$$cov(X,Y) = \frac{\sum_{i=1}^{n}(X_i-\overline{x})(Yi-\overline{Y})}{n-1}$$
协方差只能处理二维问题，那维数多了自然需要计算多个协方差，我们可以使用矩阵来组织这些数据。
协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。

<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 211105.png"  div align=center />
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-12 212001.png"  div align=center />

<center>注意一个样本为一列，一行为一个维度</center>
通过数据集的协方差矩阵及其特征值分析，我们可以得到协方差矩阵的特征向量和特征值。我们需要保留k个维度的特征就选取最大的k个特征值。
（关于协方差矩阵可以参考https://blog.csdn.net/ybdesire/article/details/6270328）