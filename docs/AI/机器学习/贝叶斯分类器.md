<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>

# 贝叶斯分类器

### 前言
**总体信息：** 当前总体样本符合某种分布。比如抛硬币，二项分布。学生的某一科的成绩符合正态分布。
**样本信息：** 通过抽样得到的部分样本的某种分布。
抽样信息=总体信息+样本信息。基于抽样信息进行统计推断的理论和方法称为经典统计学。
**先验信息：** 抽样之前，有关推断问题中未知参数的一些信息，通常来自于经验或历史资料。

基于总体信息+样本信息+先验信息进行统计推断的方法和理论，称为贝叶斯统计学。
##### 古典学派和贝叶斯学派的争论
古典统计学派认为概率来源于统计，需要通过统计来得到概率抛硬币
贝叶斯学派认为有些情况概率是来源于统计，有些情况概率来源于先验知识

* 矛盾点在于是否承认先验概率

## 贝叶斯定理
贝叶斯定理告诉我们如何交换条件概率中的条件与结果，即如果已知P(A|B)，要求P(B|A)，那么可以使用下面的计算方法：
$$P(B|A) = \frac{P(A|B)P(B)}{P(A)}$$
P（B|A）是给定观测数据样本A，假设B是成立的概率。
比如A是一份具有特定特征的邮件，B是垃圾邮件。它里面包含很多的单词（特征），然后我们判断这封邮件A属于垃圾邮件B的概率是多少。
P（B|A）是后验概率。比如一份特定邮件中，是垃圾邮件的概率。
P（B）是B的先验概率。比如总体邮件中垃圾邮件的概率。
P（A）是A的先验概率。比如总体邮件中带有特定特征的邮件概率。
可以通过抽样来计算先验概率。抽样的数量越大，得到的结果越接近于真实的概率分布-大数定理。

## 朴素贝叶斯(Naive Bayes)
由于单纯用贝叶斯定理，当特征值变多时，每个特征的影响的统计量以指数增长，为了简化计算，于是提出朴素贝叶斯。
假设：特征A1，A2，A3....之间都是相互独立的
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 163157.png"  div align=center />
如上图假设垃圾邮件中出现办证、理财、投资、资讯的事件相互独立

$$H(B|A)= \frac{P(A|B)P(B)}{P(A)} =\frac{P(A_1|B)P(A_2|B)...P(A_n|B)P(B)}{P(A_1)P(A_2)...P(A_n)}$$

### 多项式模型
事件中重复特征视为出现多次
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 163859.png"  div align=center />

### 伯努利模型
事件中重复特征视为出现一次
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 163546.png"  div align=center />

### 混合模型
训练时考虑，测试时不考虑重复特征
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 163719.png"  div align=center />

### 高斯模型
高斯模型可以解决特征取值连续的问题，将连续特征转化为离散特征。比如说人的身高，物体的长度，这些特征可以转换成离散型的值，如果身高在160cm以下，特征值为1；在160cm和170cm之间，特征值为2；在170cm之上，特征值为3。也可以这样转换，将身高转换为3个特征，分别是f1、f2、f3，如果身高是160cm以下，这三个特征的值分别是1、0、0，若身高在170cm之上，这三个特征的值分别是0、0、1。

#### 词袋模型(Bag of Words)
Bag-of-words model（BoW model）最早出现在自然语言处理（Natural Language Processing）和信息检索（Information Retrieval）领域。该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词（words）来表达一段文字或一个文档。
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 203116.png"  div align=center />

基于文本的BoW模型的一个简单例子如下：
首先给出两个简单的文本文档如下：
John likes to watch movies.Mary likes too.
John also likes to watch football games.
基于上述两个文档中出现的单词，构建如下一个词典（dictionary）：
{"John"：1，"likes"：2，"to"：3，"watch"：4，"movies"：5，"also"：6，"football"：7，"games"：8，"Mary"s9，"too"：10}

上面的词典中包含10个单词，每个单词有唯一的索引，那么每个文本我们可以使用一个10维的向量来表示。如下：
&emsp;[1，2，1，1，1，0，0，0，1，1]
&emsp;[1，1，1，1，0，1，1，1，0，0]
该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。

首先对全部文章的单词做成一个字典，并规定好在向量中相应的位置，则每篇文章的向量长度是相同的，构建模型的时候

#### TF-IDF
提取文章关键词：
1.**提取词频**（Term Frequency，缩写**TF**）。但是出现最多的词可能是“的，是，在”等对文章分类或搜索没有帮助的**停用词**
（stop words）。
2.假设我们把停用词都过滤掉了，只考虑有意义的词。可能会遇到这样一个问题，“中国”，“蜜蜂”，“养殖”这三个词的TF一样。
作为关键词，它们的重要性是一样的吗？
3.显然不是这样。因为“中国“是很常见的词，相对而言，“蜜蜂”和“养殖”不那么常见。如果这三个词在一篇文章的出现次数一样多，有理由认为，“蜜蜂”和“养殖”的重要程度要大于“中国”，也就是说，在关键词排序上面，“蜜蜂”和“养殖”应该排在“中国”的前面。
所以，我们需要一个重要性调整系数，衡量一个词是不是常见词。如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能就反映了这篇文章的特性。正是我们所需要的关键词。
用统计学语言表达，就是在词频的基础上，要对每个词分配一个“重要性“权重。最常见的词（"的"、“是”、“在”）给予最小的权重，较常见的词（“中国”）给予较小的权重，较少见的词（“蜜蜂”、“养殖”）给予较大的权重。这个权重叫做
**“逆文档频率”**（Inverse Document Frequency，缩写为**IDF**），它的大小与一个词的常见程度成反比。

#### 词频（TF）有三种常用算法（：
$$词频（TF）=某个词在文章中出现次数\tag{1}$$
$$词频（TF）=\frac{某个词在文章中出现次数}{文章总词数}\tag{2}$$
$$词频（TF）=\frac{某个词在文章中出现次数}{该文章出现最多的词的次数}\tag{3}$$
**注意** 
计算TF是基于该文章的，而不是整个语料库


#### 逆文档频率（IDF）算法：
$$逆文档频率（IDF）= log(\frac{语料库的文档总数}{包含该词的文档数+1})$$

#### TF-IDF：
$$TF-IDF = 词频（TF）× 逆文档频率（IDF）$$

#### 例子
<img src="https://gitee.com/zero049/MyNoteImages/raw/master/Annotation 2019-10-11 210037.png"  div align=center />

